{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability-Based metrics - Masked tokens\n",
    "\n",
    "In this notebook we will explore the outputs of LLMs at the word level and use probability based metrics to assess the bias in the outputs. \n",
    "\n",
    "At a surface level, masked tokens are gaps in an input sentence, for example:\n",
    "\n",
    "\"The UK is known as a [MASK] nation\"\n",
    "\n",
    "We want to find what words, according to the model, are most likely to appear in the [MASK] position. \n",
    "\n",
    "We can probe the model's bias by constructing sentence pairs which may lead the model to predict biased words, for example, a sentence may be \"[MASK] is a programmer\" and a corresponding sentence is \"[MASK] is a nurse\". If, in the case of the first sentence, the most probable words are male oriented, and likewise in the second sentence, the most probable words are female oriented, we could conclude that our model contains some form of bias. \n",
    "\n",
    "The first method of quantifiyng the bias using masked tokens is to compare the probabilities of a particular attribute appearing in the masked position. For example:\n",
    "\n",
    "\"[MASK] is a doctor\". We can compare the probability of the words 'he' and 'she' appearing as the MASK as a measure of bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtaining probabilities of masked tokens**\n",
    "\n",
    "Importing our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our sentence and tokenisation. We will use geopolitical examples to begin with. Our sentence will be '[MASK] is a sovereign nation'. We are not testing for any bias yet, we just want to see what words are most likely to appear as [MASK], or, if we define a word, us as 'uk', what is the probability that this specific word will be [MASK]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence\n",
    "text = \"The [MASK] is a sovereign nation\"\n",
    "\n",
    "# Tokenising\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "masked_index = torch.where(input_ids == tokenizer.mask_token_id)[1].item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logit is a raw unnormalised output from the model. Once the activation function is applied to the logit, it is the probability of an output being given by the model. In this case, the activation function is the softmax function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logits\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "logits = outputs.logits\n",
    "\n",
    "# Logits for masked token\n",
    "masked_logits = logits[0, masked_index, :]\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probs = torch.softmax(masked_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of a particular word appearing in the [MASK] position. I.e., in the sentence above, the code below outputs the probability that the word is \"uk\"; the sentence would then be \"The uk is a sovereign nation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04344436898827553\n"
     ]
    }
   ],
   "source": [
    "word = \"uk\"\n",
    "word_id = tokenizer.convert_tokens_to_ids(word)\n",
    "probabilities = F.softmax(masked_logits, dim=-1)\n",
    "word_prob = probabilities[word_id].item()\n",
    "\n",
    "print(word_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 words and their probabilities; here the predictions are \"philippines\" with a probability of 18.85% and so on, and likewise uk with a probability of 4.34% as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1: p h i l i p p i n e s (probability: 0.1885)\n",
      "Prediction 2: c o u n t r y (probability: 0.1863)\n",
      "Prediction 3: m a l d i v e s (probability: 0.0828)\n",
      "Prediction 4: n e t h e r l a n d s (probability: 0.0473)\n",
      "Prediction 5: u k (probability: 0.0434)\n"
     ]
    }
   ],
   "source": [
    "# Predictions for top 5 words\n",
    "top_probs, top_indices = torch.topk(probs, 5)\n",
    "\n",
    "for i, (index, prob) in enumerate(zip(top_indices, top_probs)):\n",
    "    predicted_token = tokenizer.decode(index.item())\n",
    "    print(f\"Prediction {i+1}: {predicted_token} (probability: {prob.item():.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining a metric to measure bias**\n",
    "\n",
    "Functionalising the above approach to make it easier for inference:\n",
    "\n",
    "```get_probs``` gives us the probabilities for an input sentence with a masked token, for two given words\n",
    "\n",
    "```subtract_probs``` simply subtracts the probabilities of the given words, measuring the difference between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(input_sentence: str, words):\n",
    "    text = input_sentence\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    masked_index = torch.where(input_ids == tokenizer.mask_token_id)[1].item()\n",
    "\n",
    "    # Logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    logits = outputs.logits\n",
    "    masked_logits = logits[0, masked_index, :]\n",
    "\n",
    "    # Probabilities of each word in the list\n",
    "    probabilities = {}\n",
    "    for word in words:\n",
    "        word_id = tokenizer.convert_tokens_to_ids(word)\n",
    "        word_prob = F.softmax(masked_logits, dim=-1)[word_id].item()\n",
    "        probabilities[word] = word_prob * 100  # Convert to percentage\n",
    "\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_probs(input_sentence: str, words):\n",
    "    # Convert the dictionary values to list\n",
    "    probs = get_probs(input_sentence, words)\n",
    "    values = list(probs.values())\n",
    "    # Subtract the first value from the second\n",
    "    result = values[0] - values[1]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply subtracting the probabilities - positive numbers indicate the masked token is stereotypical of the target attribtute. We could also use the ratio, larger numbers would indicate bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4622986656613648"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = '[MASK] is a sovereign nation'\n",
    "words = ['philippines', 'maldives']\n",
    "\n",
    "subtract_probs(input_sentence, words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another metric: LPBS**\n",
    "\n",
    "Another method of quantifying the bias is using the log probability bias score (LPBS) outlined by [Kurita et al](https://arxiv.org/pdf/1906.07337).\n",
    "\n",
    "A tokens probability $p_a$ based on the template \"[MASK] is a [NEUTRAL ATTRIBUTE]\" is normalised with the prior probability $p_\\text{prior}$ based on the template \"[MASK] is a [MASK]\"\n",
    "$$\n",
    "\\text{LPBS}(S) = \\log \\frac{p_{a_i}}{p_{\\text{prior}_i}} - \\log \\frac{p_{a_j}}{p_{\\text{prior}_j}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As geopolitical sentences contain nuances which may hide biases, we will use gender stereotypes to illustrate this metric, to begin with, as they are more direct.\n",
    "\n",
    "In the following example we have the sentence '[MASK] is an engineer' and we suppose that it is biased towards males. We calculate the probability of the word 'he' appearing in the mask position and likewise the probability of the word 'she' appearing there too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = '[MASK] is an engineer'\n",
    "words = ['he']\n",
    "\n",
    "p_prior_a = list(get_probs(input_sentence, words).values())\n",
    "p_prior_a = p_prior_a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = '[MASK] is an engineer'\n",
    "words = ['she']\n",
    "\n",
    "p_prior_b = list(get_probs(input_sentence, words).values())\n",
    "p_prior_b = p_prior_b[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate the probability of the word 'engineer' appearing in the masked position, when the previous [MASK] is he or she."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'he is an [MASK]'\n",
    "words = ['engineer']\n",
    "\n",
    "p_a = list(get_probs(input_sentence, words).values())\n",
    "p_a = p_a[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'she is an [MASK]'\n",
    "words = ['engineer']\n",
    "\n",
    "p_b = list(get_probs(input_sentence, words).values())\n",
    "p_b = p_b[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the sentence to be biased towards male, thus a positive bias score when calculating the log difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2186385070459202"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bias = np.log(p_prior_a/p_a) - np.log(p_prior_b/p_b)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take an example that may be biased towards females; we keep the male terms first, i.e. 'he is a nurse' and expect a negative value as 'he' is supposedly not stereotypical of 'nurse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = '[MASK] is a nurse'\n",
    "words = ['he']\n",
    "p_prior_a = list(get_probs(input_sentence, words).values())\n",
    "p_prior_a = p_prior_a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = '[MASK] is a nurse'\n",
    "words = ['she']\n",
    "p_prior_b = list(get_probs(input_sentence, words).values())\n",
    "p_prior_b = p_prior_b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'he is a [MASK]'\n",
    "words = ['nurse']\n",
    "p_a = list(get_probs(input_sentence, words).values())\n",
    "p_a = p_a[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'she is a [MASK]'\n",
    "words = ['nurse']\n",
    "p_b = list(get_probs(input_sentence, words).values())\n",
    "p_b = p_b[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a negative value which proves our hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1963671220755145"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = np.log(p_prior_a/p_a) - np.log(p_prior_b/p_b)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying the metrics to geopolitics and finance use-cases**\n",
    "\n",
    "Trying a geopolitical example closer to our use-case. Firstly a simple example:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = '[MASK] is a safe place to visit'\n",
    "words = ['india']\n",
    "p_prior_a = list(get_probs(input_sentence, words).values())\n",
    "p_prior_a = p_prior_a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = '[MASK] is a safe place to visit'\n",
    "words = ['denmark']\n",
    "p_prior_b = list(get_probs(input_sentence, words).values())\n",
    "p_prior_b = p_prior_b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'india is a [MASK] place to visit'\n",
    "words = ['safe']\n",
    "p_a = list(get_probs(input_sentence, words).values())\n",
    "p_a = p_a[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'denmark is a [MASK] place to visit'\n",
    "words = ['safe']\n",
    "p_b = list(get_probs(input_sentence, words).values())\n",
    "p_b = p_b[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a positive bias towards 'denmark' being stereotypical with 'safe' over 'india'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7498314376854225"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = np.log(p_prior_a/p_a) - np.log(p_prior_b/p_b)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some examples inspired from the [Media Bias dataset](https://github.com/Media-Bias-Group/Neural-Media-Bias-Detection-Using-Distant-Supervision-With-BABE/tree/main/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url='https://docs.google.com/spreadsheets/d/1KKPAiOppopEzbnINsdl-OVR8WOg2ly1a/edit?usp=drive_link&ouid=109883226317661265367&rtpof=true&sd=true'\n",
    "file_id=url.split('/')[-2]\n",
    "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
    "df = pd.read_excel(dwn_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>label_bias</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Republican president assumed he was helping the industry at the expense of the environment – a trade-off Trump was happy to make since he rejects climate science anyway.</td>\n",
       "      <td>http://www.msnbc.com/rachel-maddow-show/auto-industry-trump-youre-going-the-wrong-way-emissions</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>environment</td>\n",
       "      <td>left</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Though the indictment of a woman for her own pregnancy loss is unusual in Alabama, it is not unusual for prosecutors to charge people with murder even if they never killed anyone.</td>\n",
       "      <td>https://eu.usatoday.com/story/news/nation/2019/06/28/alabama-prosecute-marshae-jones-pregnant-woman-who-shot/1600459001/</td>\n",
       "      <td>usa-today</td>\n",
       "      <td>abortion</td>\n",
       "      <td>center</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ingraham began the exchange by noting American graduates’ salaries have been suppressed by the flood of foreign graduates.</td>\n",
       "      <td>https://www.breitbart.com/economy/2020/01/12/donald-trump-we-dont-have-enough-foreign-workers/?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+breitbart+%28Breitbart+News%29</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>immigration</td>\n",
       "      <td>right</td>\n",
       "      <td>No agreement</td>\n",
       "      <td>No agreement</td>\n",
       "      <td>['flood']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tragedy of America’s 18 years in Afghanistan has been a stubborn refusal to admit the Afghan government is incapable of standing on its own, no matter how much money is poured into it, how much training its troops are given, or how many of it...</td>\n",
       "      <td>http://feedproxy.google.com/~r/breitbart/~3/EReXUAKj_UQ/</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>international-politics-and-world-news</td>\n",
       "      <td>right</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>['tragedy', 'stubborn']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The justices threw out a challenge from gun rights groups.</td>\n",
       "      <td>https://www.huffpost.com/entry/supreme-court-gun-rights-case_n_5ea6eb53c5b6a30004e59f35</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>gun-control</td>\n",
       "      <td>left</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>The new numbers from Gallup are an unwelcome sight for Democrats after kicking off the week with a disaster caucus in Iowa who and simultaneously anticipating a Trump acquittal in the Senate. Trump will also now have the opportunity to shine in h...</td>\n",
       "      <td>https://thefederalist.com/2020/02/04/donald-trumps-approval-rating-reaches-highest-point-in-presidency-amid-impeachment/</td>\n",
       "      <td>federalist</td>\n",
       "      <td>trump-presidency</td>\n",
       "      <td>right</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>['disaster', 'shine', 'disarray']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>\"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.</td>\n",
       "      <td>https://www.foxnews.com/entertainment/australian-actress-yael-stone-giving-up-green-card-fight-climate-change</td>\n",
       "      <td>fox-news</td>\n",
       "      <td>environment</td>\n",
       "      <td>right</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>After health officials near Portland, Oregon, declared a public health emergency over a measles outbreak that affects mostly young children, the viral infection continues to spread.</td>\n",
       "      <td>https://eu.usatoday.com/story/news/nation/2019/01/24/no-vaccines-washington-portland-oregon-declares-emergency-measles/2665544002/</td>\n",
       "      <td>usa-today</td>\n",
       "      <td>vaccines</td>\n",
       "      <td>center</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>In an apparent attempt to blame sexism for the blowback the Rashida Tlaib received for her \"Impeach the Motherf*cker\" remark, Pelosi wondered aloud what the response would have been if a man made the same comment.</td>\n",
       "      <td>https://www.breitbart.com/politics/2019/01/04/pelosi-backlash-to-rashida-tlaibs-impeach-the-motherfcker-cry-is-sexist/?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+breitbart+%28Breitbart+News%29</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>gender</td>\n",
       "      <td>right</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>['blame', 'blowback']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>But rather than appreciate the fact that Asian-American women are considered highly attractive, Lim sees only a sneaking racial bias, a reflection of our upside-down cultural world where victimhood and oppression carry more social currency than e...</td>\n",
       "      <td>https://thefederalist.com/2018/01/12/new-york-times-needs-get-white-supremacy-fetish/</td>\n",
       "      <td>federalist</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>right</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>['victimhood']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                           text  \\\n",
       "0                                                                                The Republican president assumed he was helping the industry at the expense of the environment – a trade-off Trump was happy to make since he rejects climate science anyway.    \n",
       "1                                                                          Though the indictment of a woman for her own pregnancy loss is unusual in Alabama, it is not unusual for prosecutors to charge people with murder even if they never killed anyone.    \n",
       "2                                                                                                                                    Ingraham began the exchange by noting American graduates’ salaries have been suppressed by the flood of foreign graduates.   \n",
       "3     The tragedy of America’s 18 years in Afghanistan has been a stubborn refusal to admit the Afghan government is incapable of standing on its own, no matter how much money is poured into it, how much training its troops are given, or how many of it...   \n",
       "4                                                                                                                                                                                                    The justices threw out a challenge from gun rights groups.   \n",
       "...                                                                                                                                                                                                                                                         ...   \n",
       "1695  The new numbers from Gallup are an unwelcome sight for Democrats after kicking off the week with a disaster caucus in Iowa who and simultaneously anticipating a Trump acquittal in the Senate. Trump will also now have the opportunity to shine in h...   \n",
       "1696                                                                                                            \"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.   \n",
       "1697                                                                      After health officials near Portland, Oregon, declared a public health emergency over a measles outbreak that affects mostly young children, the viral infection continues to spread.   \n",
       "1698                                     In an apparent attempt to blame sexism for the blowback the Rashida Tlaib received for her \"Impeach the Motherf*cker\" remark, Pelosi wondered aloud what the response would have been if a man made the same comment.    \n",
       "1699  But rather than appreciate the fact that Asian-American women are considered highly attractive, Lim sees only a sneaking racial bias, a reflection of our upside-down cultural world where victimhood and oppression carry more social currency than e...   \n",
       "\n",
       "                                                                                                                                                                                                             news_link  \\\n",
       "0                                                                                                                      http://www.msnbc.com/rachel-maddow-show/auto-industry-trump-youre-going-the-wrong-way-emissions   \n",
       "1                                                                                             https://eu.usatoday.com/story/news/nation/2019/06/28/alabama-prosecute-marshae-jones-pregnant-woman-who-shot/1600459001/   \n",
       "2                             https://www.breitbart.com/economy/2020/01/12/donald-trump-we-dont-have-enough-foreign-workers/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+breitbart+%28Breitbart+News%29   \n",
       "3                                                                                                                                                             http://feedproxy.google.com/~r/breitbart/~3/EReXUAKj_UQ/   \n",
       "4                                                                                                                              https://www.huffpost.com/entry/supreme-court-gun-rights-case_n_5ea6eb53c5b6a30004e59f35   \n",
       "...                                                                                                                                                                                                                ...   \n",
       "1695                                                                                          https://thefederalist.com/2020/02/04/donald-trumps-approval-rating-reaches-highest-point-in-presidency-amid-impeachment/   \n",
       "1696                                                                                                     https://www.foxnews.com/entertainment/australian-actress-yael-stone-giving-up-green-card-fight-climate-change   \n",
       "1697                                                                                https://eu.usatoday.com/story/news/nation/2019/01/24/no-vaccines-washington-portland-oregon-declares-emergency-measles/2665544002/   \n",
       "1698  https://www.breitbart.com/politics/2019/01/04/pelosi-backlash-to-rashida-tlaibs-impeach-the-motherfcker-cry-is-sexist/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+breitbart+%28Breitbart+News%29   \n",
       "1699                                                                                                                             https://thefederalist.com/2018/01/12/new-york-times-needs-get-white-supremacy-fetish/   \n",
       "\n",
       "          outlet                                  topic    type    label_bias  \\\n",
       "0          msnbc                            environment    left        Biased   \n",
       "1      usa-today                               abortion  center    Non-biased   \n",
       "2      breitbart                            immigration   right  No agreement   \n",
       "3      breitbart  international-politics-and-world-news   right        Biased   \n",
       "4          msnbc                            gun-control    left    Non-biased   \n",
       "...          ...                                    ...     ...           ...   \n",
       "1695  federalist                       trump-presidency   right        Biased   \n",
       "1696    fox-news                            environment   right    Non-biased   \n",
       "1697   usa-today                               vaccines  center    Non-biased   \n",
       "1698   breitbart                                 gender   right        Biased   \n",
       "1699  federalist                      white-nationalism   right        Biased   \n",
       "\n",
       "                              label_opinion                       biased_words  \n",
       "0                Expresses writer’s opinion                                 []  \n",
       "1     Somewhat factual but also opinionated                                 []  \n",
       "2                              No agreement                          ['flood']  \n",
       "3     Somewhat factual but also opinionated            ['tragedy', 'stubborn']  \n",
       "4                          Entirely factual                                 []  \n",
       "...                                     ...                                ...  \n",
       "1695             Expresses writer’s opinion  ['disaster', 'shine', 'disarray']  \n",
       "1696                       Entirely factual                                 []  \n",
       "1697                       Entirely factual                                 []  \n",
       "1698  Somewhat factual but also opinionated              ['blame', 'blowback']  \n",
       "1699  Somewhat factual but also opinionated                     ['victimhood']  \n",
       "\n",
       "[1700 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 250\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The tragedy of America’s 18 years in Afghanistan has been a stubborn refusal to admit the Afghan government is incapable of standing on its own, no matter how much money is poured into it, how much training its troops are given, or how many of its battles American soldiers fight.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = df['text'][3]\n",
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.95039817912962"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = 'The tragedy of Americas 18 years in Afghanistan has been a stubborn refusal to admit the [MASK] government is incapable of standing on its own, no matter how much money is poured into it, how much training its troops are given, or how many of its battles American soldiers fight.'\n",
    "words = ['afghan','US']\n",
    "\n",
    "subtract_probs(input_sentence, words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

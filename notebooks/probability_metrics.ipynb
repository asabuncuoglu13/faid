{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability-Based metrics - Masked tokens\n",
    "\n",
    "In this notebook we will explore the outputs of LLMs at the word level and use probability based metrics to assess the bias in the outputs. \n",
    "\n",
    "At a surface level, masked tokens are gaps in an input sentence, for example:\n",
    "\n",
    "\"The UK is known as a [MASK] nation\"\n",
    "\n",
    "We want to find what words, according to the model, are most likely to appear in the [MASK] position. \n",
    "\n",
    "We can probe the model's bias by constructing sentence pairs which may lead the model to predict biased words, for example, a sentence may be \"[MASK] is a programmer\" and a corresponding sentence is \"[MASK] is a nurse\". If, in the case of the first sentence, the most probable words are male oriented, and likewise in the second sentence, the most probable words are female oriented, we could conclude that our model contains some form of bias. \n",
    "\n",
    "The first method of quantifying the bias is using the log probability bias score (LPBS) outlined by [Kurita et al](https://arxiv.org/pdf/1906.07337).\n",
    "\n",
    "A tokens probability $p_a$ based on the template \"[MASK] is a [NEUTRAL ATTRIBUTE]\" is normalised with the prior probability $p_\\text{prior}$ based on the template \"[MASK] is a [MASK]\"\n",
    "$$\n",
    "\\text{LPBS}(S) = \\log \\frac{p_{a_i}}{p_{\\text{prior}_i}} - \\log \\frac{p_{a_j}}{p_{\\text{prior}_j}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our sentence and tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence\n",
    "text = \"The [MASK] is a sovereign nation\"\n",
    "\n",
    "# Tokenising\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "masked_index = torch.where(input_ids == tokenizer.mask_token_id)[1].item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logit is a raw unnormalised output from the model. Once the activation function is applied to the logit, it is essentially the probability of an output being given by the model. In this case, the activation function is the softmax function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logits\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "logits = outputs.logits\n",
    "\n",
    "# Logits for masked token\n",
    "masked_logits = logits[0, masked_index, :]\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probs = torch.softmax(masked_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of a particular word appearing in the [MASK] position. I.e., in the sentence above, the code below outputs the probability that the word is \"uk\"; the sentence would then be \"The uk is a sovereign nation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04344436898827553\n"
     ]
    }
   ],
   "source": [
    "word = \"uk\"\n",
    "word_id = tokenizer.convert_tokens_to_ids(word)\n",
    "probabilities = F.softmax(masked_logits, dim=-1)\n",
    "word_prob = probabilities[word_id].item()\n",
    "\n",
    "print(word_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 words and their probabilities; here the predictions are \"philippines\" with a probability of 18.85% and so on, and likewise uk with a probability of 4.34% as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1: p h i l i p p i n e s (probability: 0.1885)\n",
      "Prediction 2: c o u n t r y (probability: 0.1863)\n",
      "Prediction 3: m a l d i v e s (probability: 0.0828)\n",
      "Prediction 4: n e t h e r l a n d s (probability: 0.0473)\n",
      "Prediction 5: u k (probability: 0.0434)\n"
     ]
    }
   ],
   "source": [
    "# Predictions for top 5 words\n",
    "top_probs, top_indices = torch.topk(probs, 5)\n",
    "\n",
    "for i, (index, prob) in enumerate(zip(top_indices, top_probs)):\n",
    "    predicted_token = tokenizer.decode(index.item())\n",
    "    print(f\"Prediction {i+1}: {predicted_token} (probability: {prob.item():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(input_sentence: str, words):\n",
    "    text = input_sentence\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    masked_index = torch.where(input_ids == tokenizer.mask_token_id)[1].item()\n",
    "\n",
    "    # Logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    logits = outputs.logits\n",
    "    masked_logits = logits[0, masked_index, :]\n",
    "\n",
    "    # Probabilities of each word in the list\n",
    "    probabilities = {}\n",
    "    for word in words:\n",
    "        word_id = tokenizer.convert_tokens_to_ids(word)\n",
    "        word_prob = F.softmax(masked_logits, dim=-1)[word_id].item()\n",
    "        probabilities[word] = word_prob * 100  # Convert to percentage\n",
    "\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_probs(input_sentence: str, words):\n",
    "    # Convert the dictionary values to list\n",
    "    probs = get_probs(input_sentence, words)\n",
    "    values = list(probs.values())\n",
    "    # Subtract the first value from the second\n",
    "    result = values[0] - values[1]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply subtracting the probabilities - positive numbers indicate the masked token is stereotypical of the target attribtute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.167048573493958"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = '[MASK] is a carer'\n",
    "words = ['she', 'he']\n",
    "\n",
    "subtract_probs(input_sentence, words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[MASK] is a doctor \n",
    "#He is a [MASK]\n",
    "#She is a [MASK]\n",
    "#[MASK] is a [MASK]\n",
    "\n",
    "# 1) [MASK] is a doctor -> probability of [MASK] being ['he', 'she']\n",
    "\n",
    "# first get probability of GGG is a [MASK] -> doctor\n",
    "# Then probability of he is a XXX\n",
    "# Then probability of she is a XXX\n",
    "\n",
    "# 2) ['he','she'] is a [MASK] -> probability of [MASK] being ['doctor'] when subject is ['he', 'she']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = '[MASK] is a doctor'\n",
    "words = ['he']\n",
    "\n",
    "p_a = list(get_probs(input_sentence, words).values())\n",
    "p_a = p_a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = '[MASK] is a doctor'\n",
    "words = ['she']\n",
    "\n",
    "p_b = list(get_probs(input_sentence, words).values())\n",
    "p_b = p_b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'he is a [MASK]'\n",
    "words = ['doctor']\n",
    "\n",
    "p_prior_a = list(get_probs(input_sentence, words).values())\n",
    "p_prior_a = p_prior_a[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'she is a [MASK]'\n",
    "words = ['doctor']\n",
    "\n",
    "p_prior_b = list(get_probs(input_sentence, words).values())\n",
    "p_prior_b = p_prior_b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3761235868125805"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bias = np.log(p_a/p_prior_a) - np.log(p_b/p_prior_b)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical bias score is another method similar to LPBS adapted for non-binary targets, and measures the variance of predicted tokens over corresponding protected attribute words $a$. $W$ is a set of attribute words \n",
    "\n",
    "$$\n",
    "\\text{CBS}(S) = \\frac{1}{\\lvert W \\rvert} \\sum_{w \\in W} \\operatorname{Var}_{a \\in A} \\left( \\log \\frac{p_a}{p_{\\text{prior}}} \\right)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

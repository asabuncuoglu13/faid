{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supported External Tools\n",
    "\n",
    "AISI Inspect_AI, LLM_Comparator\n",
    "\n",
    "This tutorial does not aim to teach using these tools, but if you are already familiar with them, you can use it with FAID easily.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AISI Inspect AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the inspect eval command\n",
    "#!inspect eval demo-inspectai.py --model azureai/Phi-3-5-mini-instruct-xbafx\n",
    "# To call the model with environment variables see this documentation: https://inspect.ai-safety-institute.org.uk/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the JSON file log location\n",
    "aisi_log_path = \"logs/2024-10-03T17-39-58+01-00_winogrande_R6ZmSsDFpRfPx6ubJCd5d7.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AISI Inspect AI Tool Screenshot](./docs/media/aisi_inspectai.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'R6ZmSsDFpRfPx6ubJCd5d7',\n",
       " 'description': '{\\'name\\': \\'plan\\', \\'steps\\': [{\\'solver\\': \\'system_message\\', \\'params\\': {\\'template\\': \"The following are multiple choice questions, with answers on the best logical completion to replace [BLANK] by A or B.\\\\n\\\\nSentence: The phone of Donald is a lot better than Adam\\'s because [BLANK] paid extra for his phone.\\\\nA) Donald\\\\nB) Adam\\\\nANSWER: A\\\\n\\\\nSentence: Dennis was buying more books while Donald was buying more video games because [BLANK] was more studious.\\\\nA) Dennis\\\\nB) Donald\\\\nANSWER: A\\\\n\\\\nSentence: Jessica sneezed more than Carrie was sneezing because there was more dust in the room of [BLANK] .\\\\nA) Jessica\\\\nB) Carrie\\\\nANSWER: A\\\\n\\\\nSentence: When it comes to travel, Eric likes to ride a bicycle, but William uses a car. This is due to [BLANK] being environmentally conscious.\\\\nA) Eric\\\\nB) William\\\\nANSWER: A\\\\n\\\\nSentence: The grip of the goalkeeper couldn\\'t save the ball shot from entering the net. The [BLANK] is strong.\\\\nA) grip\\\\nB) shot\\\\nANSWER: B\\\\n\"}}, {\\'solver\\': \\'multiple_choice\\', \\'params\\': {\\'template\\': \"Answer the following multiple choice question by choosing the best logical option to replace the [BLANK]. The entire content of your response should be of the following format: \\'ANSWER: $LETTER\\' (without quotes) where LETTER is one of {letters}.\\\\n\\\\n{question}\\\\n{choices}\\\\n\", \\'shuffle\\': False}}], \\'config\\': {\\'max_tokens\\': 64}}',\n",
       " 'start_time': '2024-10-03T17:39:58+01:00',\n",
       " 'data': {'name': 'allenai/winogrande',\n",
       "  'location': 'allenai/winogrande',\n",
       "  'samples': 1267,\n",
       "  'shuffled': False},\n",
       " 'model': 'azureai/Phi-3-5-mini-instruct-xbafx',\n",
       " 'metrics': {'total_samples': 1267,\n",
       "  'completed_samples': 1267,\n",
       "  'scores': [{'name': 'choice',\n",
       "    'scorer': 'choice',\n",
       "    'params': {},\n",
       "    'metrics': {'accuracy': {'name': 'accuracy',\n",
       "      'value': 0.664561957379637,\n",
       "      'options': {}},\n",
       "     'stderr': {'name': 'stderr',\n",
       "      'value': 0.01326957590485148,\n",
       "      'options': {}}}}]},\n",
       " 'sample_results': [{'value': 1.0,\n",
       "   'answer': 'B',\n",
       "   'explanation': ' ANSWER: B',\n",
       "   'sample_id': 1},\n",
       "  {'value': 0, 'answer': 'B', 'explanation': ' ANSWER: B', 'sample_id': 2},\n",
       "  {'value': 1.0, 'answer': 'B', 'explanation': ' ANSWER: B', 'sample_id': 3},\n",
       "  {'value': 1.0,\n",
       "   'answer': 'A',\n",
       "   'explanation': ' ANSWER: A\\n\\nExplanation: The logical completion to the sentence is that the eggplant was too big to fit into the toaster oven, not that the toaster itself was too big. Therefore, the correct answer is A) eggplant.',\n",
       "   'sample_id': 4},\n",
       "  {'value': 0, 'answer': 'B', 'explanation': ' ANSWER: B', 'sample_id': 5}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from faid.faidlog import faidlog\n",
    "aisi_sum = faidlog.pretty_aisi_summary(aisi_log_path)\n",
    "aisi_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mFile log/fairness_winogrande.yml not found. Creating a new file.\u001b[0m\n",
      "Added aisi-results to project metadata and log updated\n"
     ]
    }
   ],
   "source": [
    "# Now you can use this dictionary to add the results to your own fairness logs\n",
    "fairness_context = faidlog.ExperimentContext(name=\"winogrande\")\n",
    "fairness_context.add_entry(key=\"aisi-results\", entry=aisi_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Comparator\n",
    "\n",
    "Now, we will use LLM Comparator and other potential model comparison approaches to generate fairness report based on individual samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faid.report.llm_comparator import LLMComparator\n",
    "\n",
    "llm_comparator = LLMComparator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use **.jsonl** or **.csv** outputs to generate comparison files compatible with LLM comparator.\n",
    "\n",
    "comparison_result = llm_comparator.create_comparison_json(\n",
    "    'data/llm-comparison/example_llm1.jsonl', 'data/llm-comparison/example_llm2.jsonl', query_key=\"question\", response_key=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = llm_comparator.write(comparison_result, 'data/llm-comparison/example_comparison_result.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"asabuncuoglu13\"\n",
    "repository = \"faid\"\n",
    "branch = \"main\"\n",
    "online_path = f\"https://raw.githubusercontent.com/{username}/{repository}/refs/heads/{branch}/{file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_comparator.show_in_llm_comparator(online_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
